{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IgIoPDTvjiM"
      },
      "source": [
        "#Install yolov8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XFarYchvgLt",
        "outputId": "8c3f310f-6def-4c12-84c2-4e9ff5ae1dba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ultralytics YOLOv8.0.196 ðŸš€ Python-3.10.12 torch-2.3.0+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 30.2/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics==8.0.196\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip uninstall opencv-python-headless -y\n",
        "!pip uninstall opencv-python -y\n",
        "!pip install opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python==4.5.5.62\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "display.clear_output()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ultralytics\n",
        "ultralytics.checks()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install keras\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mounting drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# enter your credentials files path here\n",
        "creds_file_path = \"/home/jovyan/client_secret_1064575295729-8ncp8e1gi66q3rnifh3q8mlgte3rmre2.apps.googleusercontent.com.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip3 install google-auth google-api-python-client google-auth-oauthlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2.credentials import Credentials\n",
        "from googleapiclient.http import MediaFileUpload, MediaIoBaseDownload\n",
        "from google_auth_oauthlib.flow import InstalledAppFlow\n",
        "\n",
        "# Define the scopes\n",
        "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
        "\n",
        "# Load existing credentials if available\n",
        "creds = None\n",
        "if os.path.exists(\"token.json\"):\n",
        "    creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
        "\n",
        "# If credentials are missing or expired, initiate OAuth flow\n",
        "if not creds or not creds.valid:\n",
        "    flow = InstalledAppFlow.from_client_secrets_file(\n",
        "        creds_file_path,\n",
        "        SCOPES,\n",
        "        redirect_uri='https://gpu-notebooks.e2enetworks.com/oauth2callback/'\n",
        "    )\n",
        "    authorization_url, _ = flow.authorization_url(prompt='consent')\n",
        "    print(f'Please go to this URL: {authorization_url}')\n",
        "\n",
        "    authorization_code = input('Enter the authorization code: ')\n",
        "    flow.fetch_token(code=authorization_code)\n",
        "    creds = flow.credentials\n",
        "\n",
        "    # Save the updated credentials for future use\n",
        "    with open(\"token.json\", \"w\") as token:\n",
        "        token.write(creds.to_json())\n",
        "\n",
        "# Build the Drive API service\n",
        "drive_service = build('drive', 'v3', credentials=creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "#FILE\n",
        "# Define your query to search for a specific file by name\n",
        "file_name = \"b.mp4\"  # Replace with your actual file name\n",
        "query = f\"name = '{file_name}'\"\n",
        "\n",
        "# Execute the query to search for the file\n",
        "results = drive_service.files().list(q=query, fields=\"files(id, name, mimeType)\").execute()\n",
        "items = results.get(\"files\", [])\n",
        "\n",
        "# Check if any files matching the query were found\n",
        "if not items:\n",
        "    print(f'No file named \"{file_name}\" found.')\n",
        "else:\n",
        "    print(f'Files named \"{file_name}\":')\n",
        "    for item in items:\n",
        "        print(f\"{item['name']} ({item['id']}) - {item['mimeType']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#FILE\n",
        "# Define the file ID you want to retrieve\n",
        "file_id = '1--y7mnOkPgWHZ_sIHWTs4VyE9G-rT9Fd'  # Replace with the actual file ID\n",
        "\n",
        "# Fetch metadata for the specified file ID\n",
        "file = drive_service.files().get(fileId=file_id, fields=\"id, name, mimeType\").execute()\n",
        "\n",
        "# Check if the file exists\n",
        "if file:\n",
        "    print(f\"File found:\")\n",
        "    print(f\"{file['name']} ({file['id']}) - {file['mimeType']}\")\n",
        "else:\n",
        "    print(f'File with ID \"{file_id}\" not found.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_id = '1--y7mnOkPgWHZ_sIHWTs4VyE9G-rT9Fd'\n",
        "file_path = '/home/jovyan/b.mp4'\n",
        "\n",
        "request = drive_service.files().get_media(fileId=file_id)\n",
        "fh = io.FileIO(file_path, mode='wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    status, done = downloader.next_chunk()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-8xlh_wwSEt"
      },
      "source": [
        "#Install Roboflow Supervision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ONn5YEewI4v"
      },
      "source": [
        "#prediction of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPk0xMKIcXSt",
        "outputId": "87ec9b5e-f568-4d59-94b6-24755c794c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video downsampling complete.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from collections import defaultdict, deque\n",
        "from ultralytics import YOLO\n",
        "from keras import models, layers, optimizers, callbacks\n",
        "import threading\n",
        "import queue\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Load YOLOv8 model from Ultralytics hub\n",
        "model = YOLO('/content/drive/MyDrive/Road_furniture_weights/content/runs/detect/train/weights/best.pt')  # Update with your model path\n",
        "\n",
        "# Initialize video capture\n",
        "video_path = '/content/drive/MyDrive/b.mp4'  # Replace with the path to your video file\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "# Get video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define object tracker class\n",
        "class ObjectTracker:\n",
        "    def __init__(self):\n",
        "        self.objects = {}\n",
        "        self.next_id = 0\n",
        "        self.distance_threshold = 50  # Distance threshold for matching objects\n",
        "\n",
        "    def update(self, box, label):\n",
        "        center = (box[0], box[1])\n",
        "        matched_id = None\n",
        "        for obj_id, obj in self.objects.items():\n",
        "            dist = np.linalg.norm(np.array(center) - np.array(obj['center']))\n",
        "            if dist < self.distance_threshold:\n",
        "                matched_id = obj_id\n",
        "                break\n",
        "\n",
        "        if matched_id is None:\n",
        "            matched_id = self.next_id\n",
        "            self.next_id += 1\n",
        "            total_counts[label] += 1  # Only increment when a new object is found\n",
        "\n",
        "        self.objects[matched_id] = {'center': center, 'label': label}\n",
        "\n",
        "# Initialize tracking history\n",
        "track_history = defaultdict(lambda: deque(maxlen=30))\n",
        "tracker = ObjectTracker()\n",
        "\n",
        "total_counts = defaultdict(int)\n",
        "\n",
        "# Object counts and frame tracking\n",
        "object_counts = defaultdict(list)\n",
        "frames = []\n",
        "train_losses = []\n",
        "\n",
        "# Data collection for training\n",
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\n",
        "    'cautionary': [1, 0, 0],\n",
        "    'mandatory': [0, 1, 0],\n",
        "    'informatory': [0, 0, 1]\n",
        "}\n",
        "\n",
        "# Define a neural network model for multi-class classification\n",
        "nn_model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(4,)),  # 4 features: x, y, width, height\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(3, activation='softmax')  # Three units for three classes\n",
        "])\n",
        "nn_model.compile(optimizer=optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Custom callback for real-time training loss visualization\n",
        "class TrainingLossPlotter(callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        train_losses.append(logs['loss'])\n",
        "\n",
        "# Initialize the callback\n",
        "loss_plotter = TrainingLossPlotter()\n",
        "\n",
        "# Function to train the model in a separate thread\n",
        "def train_model(X, y, queue):\n",
        "    history = nn_model.fit(X, y, epochs=50, batch_size=32, callbacks=[loss_plotter], validation_split=0.2)\n",
        "    queue.put(history)\n",
        "\n",
        "# CSV file path for object information\n",
        "csv_file_path = '/content/drive/MyDrive/detected_objects---.csv'\n",
        "csv_columns = ['object_id', 'timestamp', 'label', 'x', 'y', 'width', 'height']\n",
        "\n",
        "# Open CSV file for writing\n",
        "with open(csv_file_path, mode='w', newline='') as csv_file:\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=csv_columns)\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Define output video path\n",
        "    output_video_path = '/content/drive/MyDrive/video_counts---.mp4'  # Replace with your desired output path\n",
        "\n",
        "    # Explicitly set codec for compatibility\n",
        "    codec = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "    # Initialize video writer\n",
        "    out = cv2.VideoWriter(output_video_path, codec, fps, (frame_width, frame_height))\n",
        "\n",
        "    # Check if video writer is opened\n",
        "    if not out.isOpened():\n",
        "        print(\"Error: Could not open output video file for writing.\")\n",
        "    else:\n",
        "        print(\"Output video file opened successfully.\")\n",
        "\n",
        "        # Start the timer\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Data collection and visualization loop\n",
        "        frame_count = 0\n",
        "        training_started = False\n",
        "        training_queue = queue.Queue()\n",
        "        recorded_objects = set()  # Set to track recorded object IDs\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Perform object detection and tracking\n",
        "            results = model(frame, conf=0.4, iou=0.4)  # Adjust confidence threshold as needed\n",
        "\n",
        "            current_counts = defaultdict(int)\n",
        "            boxes = results[0].boxes.xywh.cpu().numpy()  # Extract bounding boxes (x, y, width, height)\n",
        "            class_ids = results[0].boxes.cls.cpu().numpy()  # Extract class labels\n",
        "\n",
        "            for box, class_id in zip(boxes, class_ids):\n",
        "                label = model.names[int(class_id)]\n",
        "                tracker.update(box, label)\n",
        "\n",
        "                obj_id = tracker.next_id - 1  # Use the current next_id\n",
        "                if obj_id not in recorded_objects:\n",
        "                    # Calculate timestamp in hr:min:sec format\n",
        "                    elapsed_seconds = frame_count / fps\n",
        "                    timestamp = time.strftime('%H:%M:%S', time.gmtime(elapsed_seconds))\n",
        "\n",
        "                    # Prepare object information for CSV\n",
        "                    obj_info = {\n",
        "                        'object_id': obj_id,\n",
        "                        'timestamp': timestamp,\n",
        "                        'label': label,\n",
        "                        'x': box[0],\n",
        "                        'y': box[1],\n",
        "                        'width': box[2],\n",
        "                        'height': box[3]\n",
        "                    }\n",
        "\n",
        "                    # Write object info to CSV\n",
        "                    writer.writerow(obj_info)\n",
        "                    print(f\"Detected object: {obj_info}\")  # Debug print statement\n",
        "\n",
        "                    recorded_objects.add(obj_id)  # Mark object as recorded\n",
        "\n",
        "                # Collect training data\n",
        "                if label in label_mapping:\n",
        "                    X_train.append([box[0], box[1], box[2], box[3]])\n",
        "                    y_train.append(label_mapping[label])\n",
        "\n",
        "                # Update tracking history\n",
        "                track = track_history[class_id]\n",
        "                track.append((float(box[0]), float(box[1])))  # x, y center point\n",
        "\n",
        "            frame_with_boxes = results[0].plot()  # Get the frame with bounding boxes\n",
        "\n",
        "            # Plot the tracks\n",
        "            for track_id, track in track_history.items():\n",
        "                points = np.array(track).astype(np.int32).reshape((-1, 1, 2))\n",
        "                cv2.polylines(frame_with_boxes, [points], isClosed=False, color=(230, 230, 230), thickness=2)\n",
        "\n",
        "            # Display total object counts on the frame\n",
        "            y_pos = 50\n",
        "            for label, count in total_counts.items():\n",
        "                cv2.putText(frame_with_boxes, f'{label}: {count}', (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX,  1, (0, 255, 0), 3)\n",
        "                y_pos += 30\n",
        "\n",
        "            # Write the frame with boxes to the output video\n",
        "            out.write(frame_with_boxes)\n",
        "            print(f\"Frame {frame_count} written to output video.\")  # Debug print statement\n",
        "\n",
        "            frame_count += 1\n",
        "\n",
        "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        # Wait for training to complete if it has started\n",
        "        if training_started:\n",
        "            training_thread.join()\n",
        "            history = training_queue.get()\n",
        "            print(\"Training completed.\")\n",
        "\n",
        "            # Save model weights\n",
        "            nn_model.save_weights('model.weights.h5')\n",
        "\n",
        "        # End the timer and print the elapsed time\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        elapsed_time_str = time.strftime('%H:%M:%S', time.gmtime(elapsed_time))\n",
        "        print(f\"Total time required to run the code: {elapsed_time_str}\")\n",
        "\n",
        "    # Close the CSV file\n",
        "    print(\"Closing CSV file.\")\n",
        "    csv_file.close()\n",
        "\n",
        "# Release video capture\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "# Debug: Print final total counts\n",
        "print(\"Final total counts:\", dict(total_counts))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
